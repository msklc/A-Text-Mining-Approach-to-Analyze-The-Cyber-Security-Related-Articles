{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Text Mining Approach to Analyze The Cyber Security Related Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART-3: Text Mining\n",
    "\n",
    "__Feature Engineering with NLP techniques__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing of Required Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from autocorrect import Speller\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading Data__\n",
    "\n",
    "As mentioned Part-2 that pandas parquet options doesn't support timedelta type. So we need to use __fastparquet__ option, to keep the timedelta type format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>AwardEffectiveDate</th>\n",
       "      <th>AwardExpirationDate</th>\n",
       "      <th>AwardAmount</th>\n",
       "      <th>ProgramOfficer</th>\n",
       "      <th>Institution_Name</th>\n",
       "      <th>Institution_StateName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Award_Duration</th>\n",
       "      <th>AwardAmount_Million</th>\n",
       "      <th>Abstract_Lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>Collaborative Research Testing Affect Control ...</td>\n",
       "      <td>2001-08-15</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>Patricia White</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1081 days</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>Federal Cyber Service Initiative</td>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>2007-06-30</td>\n",
       "      <td>149995.0</td>\n",
       "      <td>Timothy V. Fossum</td>\n",
       "      <td>University of Tulsa</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2220 days</td>\n",
       "      <td>0.15</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                         AwardTitle  \\\n",
       "0  0110599  Collaborative Research Testing Affect Control ...   \n",
       "1  0112426                   Federal Cyber Service Initiative   \n",
       "\n",
       "  AwardEffectiveDate AwardExpirationDate  AwardAmount     ProgramOfficer  \\\n",
       "0         2001-08-15          2004-07-31     300000.0     Patricia White   \n",
       "1         2001-06-01          2007-06-30     149995.0  Timothy V. Fossum   \n",
       "\n",
       "        Institution_Name Institution_StateName  \\\n",
       "0  University of Arizona               Arizona   \n",
       "1    University of Tulsa              Oklahoma   \n",
       "\n",
       "                                            Abstract  Year Award_Duration  \\\n",
       "0  The investigators will conduct a series of exp...  2001      1081 days   \n",
       "1  This program produces a cadre of computer scie...  2001      2220 days   \n",
       "\n",
       "   AwardAmount_Million  Abstract_Lenght  \n",
       "0                 0.30             2194  \n",
       "1                 0.15              765  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum=pd.read_parquet('df_sum_parquet.gzip',engine='fastparquet')\n",
    "df_investigator_cyber=pd.read_parquet('df_investigator_cyber_parque.gzip',engine='fastparquet')\n",
    "df_sum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-) Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replacing Of Contraction Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>AwardEffectiveDate</th>\n",
       "      <th>AwardExpirationDate</th>\n",
       "      <th>AwardAmount</th>\n",
       "      <th>ProgramOfficer</th>\n",
       "      <th>Institution_Name</th>\n",
       "      <th>Institution_StateName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Award_Duration</th>\n",
       "      <th>AwardAmount_Million</th>\n",
       "      <th>Abstract_Lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>Collaborative Research Testing Affect Control ...</td>\n",
       "      <td>2001-08-15</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>Patricia White</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1081 days</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>Federal Cyber Service Initiative</td>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>2007-06-30</td>\n",
       "      <td>149995.0</td>\n",
       "      <td>Timothy V. Fossum</td>\n",
       "      <td>University of Tulsa</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2220 days</td>\n",
       "      <td>0.15</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                         AwardTitle  \\\n",
       "0  0110599  Collaborative Research Testing Affect Control ...   \n",
       "1  0112426                   Federal Cyber Service Initiative   \n",
       "\n",
       "  AwardEffectiveDate AwardExpirationDate  AwardAmount     ProgramOfficer  \\\n",
       "0         2001-08-15          2004-07-31     300000.0     Patricia White   \n",
       "1         2001-06-01          2007-06-30     149995.0  Timothy V. Fossum   \n",
       "\n",
       "        Institution_Name Institution_StateName  \\\n",
       "0  University of Arizona               Arizona   \n",
       "1    University of Tulsa              Oklahoma   \n",
       "\n",
       "                                            Abstract  Year Award_Duration  \\\n",
       "0  The investigators will conduct a series of exp...  2001      1081 days   \n",
       "1  This program produces a cadre of computer scie...  2001      2220 days   \n",
       "\n",
       "   AwardAmount_Million  Abstract_Lenght  \n",
       "0                 0.30             2194  \n",
       "1                 0.15              765  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace contraction words to alternative forms before tokenization\n",
    "replacement_patterns = {\n",
    "    r\"won\\'t\": \"will not\",\n",
    "    r\"can\\'t\": \"cannot\",\n",
    "    r\"i\\'m\": \"i am\",\n",
    "    r\"ain\\'t\": \"is not\",\n",
    "    r\"(\\w+)\\'ll\": \"\\g<1> will\",\n",
    "    r\"(\\w+)n\\'t\": \"\\g<1> not\",\n",
    "    r\"(\\w+)\\'ve\": \"\\g<1> have\",\n",
    "    r\"(\\w+)\\'s\": \"\\g<1> is\",\n",
    "    r\"(\\w+)\\'re\": \"\\g<1> are\",\n",
    "    r\"(\\w+)\\'d\": \"\\g<1> would\",\n",
    "    r\"&\": \"and\",\n",
    "    r\"<br/>\":\" \"}\n",
    "\n",
    "df_sum['Abstract']=df_sum['Abstract'].replace(replacement_patterns, regex=True)\n",
    "df_sum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merge All Values in Abstract Columns to A Single String__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total character number of all Abstract columns is: 17055166\n"
     ]
    }
   ],
   "source": [
    "abstract_list=df_sum['Abstract'].tolist()\n",
    "abstract_sum=' '.join(abstract_list)\n",
    "print('Total character number of all Abstract columns is: {}'.format(len(abstract_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenization and LowerCase__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lowercase words: 2669124\n"
     ]
    }
   ],
   "source": [
    "#word tokenization\n",
    "wrd_list = nltk.word_tokenize(abstract_sum)\n",
    "\n",
    "#lowercase\n",
    "wrd_list=[w.lower() for w in wrd_list]\n",
    "print('Total lowercase words: {}'.format(len(wrd_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 2318555\n"
     ]
    }
   ],
   "source": [
    "#remove numbers\n",
    "wrd_list_alpha=[w for w in wrd_list if w.isalpha()]\n",
    "print('Total words consist of only alphabets: {}'.format(len(wrd_list_alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Written Form of Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 2312021\n"
     ]
    }
   ],
   "source": [
    "#Create numbers in written form for ignoring\n",
    "num_written= {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', \\\n",
    "             6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 10: 'ten', \\\n",
    "            11: 'eleven', 12: 'twelve', 13: 'thirteen', 14: 'fourteen', \\\n",
    "            15: 'fifteen', 16: 'sixteen', 17: 'seventeen', 18: 'eighteen', \\\n",
    "            19: 'nineteen', 20: 'twenty', 30: 'thirty', 40: 'forty', \\\n",
    "            50: 'fifty', 60: 'sixty', 70: 'seventy', 80: 'eighty', \\\n",
    "            90: 'ninety', 0: 'zero'}\n",
    "\n",
    "num_list=list(np.arange(0,100))\n",
    "\n",
    "num2words_list=[]\n",
    "\n",
    "def num2words(n):\n",
    "    try:\n",
    "        return num_written[n]\n",
    "    except:\n",
    "        try:\n",
    "            return num2words(n-n%10) + num2words(n%10)\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "        \n",
    "for num in num_list:\n",
    "    num2words_list.append(num2words(num))\n",
    "    \n",
    "wrd_list_rm_written_form = [w for w in wrd_list_alpha if w not in num2words_list]\n",
    "print('Total words consist of only alphabets: {}'.format(len(wrd_list_rm_written_form)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Stopwords__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing stopwords: 1414326\n"
     ]
    }
   ],
   "source": [
    "#define stopwords list\n",
    "stopwords_list=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#extend the stopwords list\n",
    "stopwords_list.extend(['cannot','many','much','also','well','better','via'])\n",
    "\n",
    "wrd_list_rm_stopwords = [w for w in wrd_list_rm_written_form if w not in stopwords_list]\n",
    "print('Total words after removing stopwords: {}'.format(len(wrd_list_rm_stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove 1-Length Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing 1-len words: 1413212\n"
     ]
    }
   ],
   "source": [
    "#remove 1-len words\n",
    "wrd_list_one_len = [w for w in wrd_list_rm_stopwords if len(w)>=2]\n",
    "\n",
    "print('Total words after removing 1-len words: {}'.format(len(wrd_list_one_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Counting The Words Frequency__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words before lemmatization: 32965\n"
     ]
    }
   ],
   "source": [
    "freq_dict_before=nltk.FreqDist(wrd_list_one_len)\n",
    "print('Total unique words before lemmatization: {}'.format(len(freq_dict_before)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 frequency words:\n",
      "[('research', 19624), ('project', 16513), ('data', 12358), ('systems', 9147), ('students', 9052), ('new', 8583), ('science', 7363), ('security', 5927), ('development', 5220), ('system', 5189), ('information', 5066), ('program', 4725), ('support', 4665), ('design', 4638), ('education', 4430), ('engineering', 4424), ('university', 4368), ('network', 4344), ('using', 4343), ('develop', 4295), ('community', 4291), ('learning', 4287), ('use', 4228), ('software', 4049), ('provide', 3953), ('materials', 3869), ('tools', 3679), ('technology', 3587), ('cyberinfrastructure', 3458), ('applications', 3353), ('researchers', 3284), ('broader', 3278), ('computing', 3248), ('work', 3210), ('cybersecurity', 3193), ('infrastructure', 3101), ('control', 3082), ('nsf', 3076), ('computational', 3055), ('computer', 3046), ('scientific', 3045), ('analysis', 3042), ('methods', 3036), ('high', 2969), ('including', 2938), ('used', 2913), ('award', 2896), ('national', 2846), ('impact', 2801), ('models', 2761)]\n"
     ]
    }
   ],
   "source": [
    "print('First 50 frequency words:\\n{}'.format(freq_dict_before.most_common(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words after lemmatization: 29316\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wrd_list_lemmas = [lemmatizer.lemmatize(w) for w in wrd_list_one_len]\n",
    "\n",
    "#Recounting the Words Frequency\n",
    "freq_dict=nltk.FreqDist(wrd_list_lemmas)\n",
    "\n",
    "print('Total unique words after lemmatization: {}'.format(len(freq_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 frequency words:\n",
      "[('research', 19634), ('project', 18206), ('system', 14336), ('data', 12358), ('student', 10612), ('new', 8583), ('science', 8549), ('network', 6920), ('program', 6462), ('security', 5927), ('technology', 5892), ('community', 5716), ('support', 5579), ('impact', 5509), ('development', 5476), ('university', 5085), ('information', 5066), ('design', 5035), ('model', 4935), ('application', 4789), ('material', 4609), ('tool', 4439), ('education', 4433), ('engineering', 4424), ('using', 4343), ('develop', 4295), ('learning', 4287), ('use', 4228), ('software', 4051), ('provide', 3953), ('approach', 3580), ('process', 3561), ('method', 3535), ('infrastructure', 3523), ('cyberinfrastructure', 3458), ('researcher', 3441), ('computer', 3424), ('resource', 3423), ('study', 3381), ('activity', 3380), ('analysis', 3368), ('work', 3324), ('broader', 3278), ('control', 3252), ('computing', 3248), ('cybersecurity', 3193), ('nsf', 3078), ('computational', 3055), ('scientific', 3045), ('workshop', 3015)]\n"
     ]
    }
   ],
   "source": [
    "print('First 50 frequency words:\\n{}'.format(freq_dict.most_common(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Saving The Result__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>research</td>\n",
       "      <td>19634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project</td>\n",
       "      <td>18206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system</td>\n",
       "      <td>14336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  Count\n",
       "0  research  19634\n",
       "1   project  18206\n",
       "2    system  14336"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FreqDist=pd.DataFrame({'Words':list(freq_dict.keys()),'Count':list(freq_dict.values())})\n",
    "df_FreqDist.sort_values(by=['Count'],ascending=False,inplace=True)\n",
    "df_FreqDist=df_FreqDist.reset_index(drop=True)\n",
    "df_FreqDist.to_csv('FreqDist.csv')\n",
    "df_FreqDist.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) Clustering and Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2=df_sum[['AwardID','Abstract']][:30]\n",
    "df_sum2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract\n",
       "0  0110599  The investigators will conduct a series of exp...\n",
       "1  0112426  This program produces a cadre of computer scie..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replacing Of Contraction Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract\n",
       "0  0110599  The investigators will conduct a series of exp...\n",
       "1  0112426  This program produces a cadre of computer scie..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_patterns = {\n",
    "    r\"won\\'t\": \"will not\",\n",
    "    r\"can\\'t\": \"cannot\",\n",
    "    r\"i\\'m\": \"i am\",\n",
    "    r\"ain\\'t\": \"is not\",\n",
    "    r\"(\\w+)\\'ll\": \"\\g<1> will\",\n",
    "    r\"(\\w+)n\\'t\": \"\\g<1> not\",\n",
    "    r\"(\\w+)\\'ve\": \"\\g<1> have\",\n",
    "    r\"(\\w+)\\'s\": \"\\g<1> is\",\n",
    "    r\"(\\w+)\\'re\": \"\\g<1> are\",\n",
    "    r\"(\\w+)\\'d\": \"\\g<1> would\",\n",
    "    r\"&\": \"and\",\n",
    "    r\"<br/>\":\" \"}\n",
    "\n",
    "df_sum2['Abstract'].replace(replacement_patterns, regex=True, inplace=True)\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenization and LowerCase__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 9647\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[the, investigators, will, conduct, a, series,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[this, program, produces, a, cadre, of, comput...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [the, investigators, will, conduct, a, series,...  \n",
       "1  [this, program, produces, a, cadre, of, comput...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenization and lowercase\n",
    "df_sum2['Abstract_Tokens'] = df_sum2['Abstract'].str.lower().apply(nltk.word_tokenize)\n",
    "print('Total words: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 8325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[the, investigators, will, conduct, a, series,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[this, program, produces, a, cadre, of, comput...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [the, investigators, will, conduct, a, series,...  \n",
       "1  [this, program, produces, a, cadre, of, comput...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove numbers\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if w.isalpha()]\n",
    "print('Total words consist of only alphabets: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Written Form of Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 8325\n"
     ]
    }
   ],
   "source": [
    "#Create numbers in written form for ignoring\n",
    "num_written= {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', \\\n",
    "             6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 10: 'ten', \\\n",
    "            11: 'eleven', 12: 'twelve', 13: 'thirteen', 14: 'fourteen', \\\n",
    "            15: 'fifteen', 16: 'sixteen', 17: 'seventeen', 18: 'eighteen', \\\n",
    "            19: 'nineteen', 20: 'twenty', 30: 'thirty', 40: 'forty', \\\n",
    "            50: 'fifty', 60: 'sixty', 70: 'seventy', 80: 'eighty', \\\n",
    "            90: 'ninety', 0: 'zero'}\n",
    "\n",
    "num_list=list(np.arange(0,100))\n",
    "\n",
    "num2words_list=[]\n",
    "\n",
    "def num2words(n):\n",
    "    try:\n",
    "        return num_written[n]\n",
    "    except:\n",
    "        try:\n",
    "            return num2words(n-n%10) + num2words(n%10)\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "        \n",
    "for num in num_list:\n",
    "    num2words_list.append(num2words(num))\n",
    "    \n",
    "df_sum2['Abstract_Tokens'] = df_sum2['Abstract_Tokens'].replace([w for w in num2words_list],'')\n",
    "\n",
    "print('Total words consist of only alphabets: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Stopwords__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing stopwords: 5044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigators, conduct, series, experiments, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produces, cadre, computer, scientist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [investigators, conduct, series, experiments, ...  \n",
       "1  [program, produces, cadre, computer, scientist...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define stopwords list\n",
    "stopwords_list=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#extend the stopwords list\n",
    "stopwords_list.extend(['cannot','many','much','also','well','better','via'])\n",
    "\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if w not in stopwords_list]\n",
    "print('Total words after removing stopwords: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove 1-Length Words__\n",
    "\n",
    "Punctuation\n",
    "Punctuation are the unnecessary symbols that are in our corpus documents,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing 1-len words: 5037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigators, conduct, series, experiments, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produces, cadre, computer, scientist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [investigators, conduct, series, experiments, ...  \n",
       "1  [program, produces, cadre, computer, scientist...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove 1-len words\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if len(w)>=2]\n",
    "print('Total words after removing 1-len words: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after lemmatization: 5037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigators, conduct, series, experiments, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produces, cadre, computer, scientist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [investigators, conduct, series, experiments, ...  \n",
       "1  [program, produces, cadre, computer, scientist...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n])]\n",
    "\n",
    "print('Total words after lemmatization: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words after lemmatization: 29316\n"
     ]
    }
   ],
   "source": [
    "#Recounting the Words Frequency\n",
    "freq_dict=nltk.FreqDist(wrd_list_lemmas)\n",
    "\n",
    "print('Total unique words after lemmatization: {}'.format(len(freq_dict)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
